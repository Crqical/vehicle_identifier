{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de36f231-1a5b-4265-b8cf-f25d5b19a943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pathlib in /opt/conda/lib/python3.12/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (2.3.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.12/site-packages (12.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.12/site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.12/site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/conda/lib/python3.12/site-packages (from torch) (2025.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /opt/conda/lib/python3.12/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /opt/conda/lib/python3.12/site-packages (from torch) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from torchvision) (2.3.5)\n",
      "Requirement already satisfied: torch==2.9.1 in /opt/conda/lib/python3.12/site-packages (from torchvision) (2.9.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (2025.12.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /opt/conda/lib/python3.12/site-packages (from torch==2.9.1->torchvision) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.9.1->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch==2.9.1->torchvision) (3.0.2)\n",
      "Using cached torchvision-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "Installing collected packages: torchvision\n",
      "Successfully installed torchvision-0.24.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pathlib\n",
    "%pip install numpy\n",
    "%pip install pandas\n",
    "%pip install pillow\n",
    "%pip install torch\n",
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7c175cc-cc26-480e-96f7-a22238452265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67bd4279-0bd6-46c3-8339-b8d02f11825d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === PATHS â€“ ADJUST THESE IF NEEDED ===\n",
    "# Root folder that contains subfolders like:\n",
    "# picture/2nd_Ave_49_st, picture/Queens_Midtown_Tunnel, ...\n",
    "BASE_PICTURE_DIR = Path(\"picture\")\n",
    "\n",
    "# Folder that contains JSON label files like:\n",
    "# 2nd_Ave_49_st_labels.json, Queens_Midtown_Tunnel_labels.json, ...\n",
    "# If yours are in \"car_counter/labels\", change this to Path(\"car_counter/labels\")\n",
    "LABELS_DIR = Path(\"labels\")\n",
    "\n",
    "# Where to save the trained model\n",
    "MODEL_DIR = Path(\"models\")\n",
    "MODEL_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "MODEL_PATH = MODEL_DIR / \"car_count_cnn.pth\"\n",
    "\n",
    "# Training config\n",
    "IMAGE_SIZE = 224      # images will be resized to 224x224\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 15\n",
    "LEARNING_RATE = 1e-4\n",
    "VAL_SPLIT = 0.2       # 80% train, 20% validation\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db939811-d14f-4b83-aa32-be110da5cdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total labeled images: 15\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>description</th>\n",
       "      <th>filename</th>\n",
       "      <th>car_amount</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>description_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>picture/2nd_Ave_49_st/2nd_Ave_49_st_1.png</td>\n",
       "      <td>2nd_Ave_49_st</td>\n",
       "      <td>2nd_Ave_49_st_1.png</td>\n",
       "      <td>9</td>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>12-57-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>picture/2nd_Ave_49_st/2nd_Ave_49_st_2.png</td>\n",
       "      <td>2nd_Ave_49_st</td>\n",
       "      <td>2nd_Ave_49_st_2.png</td>\n",
       "      <td>6</td>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>12-58-30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>picture/E_63_St/E_63_St_1.png</td>\n",
       "      <td>E_63_St</td>\n",
       "      <td>E_63_St_1.png</td>\n",
       "      <td>7</td>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>12-57-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>picture/Queens_Midtown_Tunnel/Queens_Midtown_T...</td>\n",
       "      <td>Queens_Midtown_Tunnel</td>\n",
       "      <td>Queens_Midtown_Tunnel_1.png</td>\n",
       "      <td>7</td>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>12-57-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>picture/Queens_Plaza_North/Queens_Plaza_North_...</td>\n",
       "      <td>Queens_Plaza_North</td>\n",
       "      <td>Queens_Plaza_North_1.png</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-12-08</td>\n",
       "      <td>12-57-30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath            description  \\\n",
       "0          picture/2nd_Ave_49_st/2nd_Ave_49_st_1.png          2nd_Ave_49_st   \n",
       "1          picture/2nd_Ave_49_st/2nd_Ave_49_st_2.png          2nd_Ave_49_st   \n",
       "2                      picture/E_63_St/E_63_St_1.png                E_63_St   \n",
       "3  picture/Queens_Midtown_Tunnel/Queens_Midtown_T...  Queens_Midtown_Tunnel   \n",
       "4  picture/Queens_Plaza_North/Queens_Plaza_North_...     Queens_Plaza_North   \n",
       "\n",
       "                      filename  car_amount        date      time  \\\n",
       "0          2nd_Ave_49_st_1.png           9  2025-12-08  12-57-30   \n",
       "1          2nd_Ave_49_st_2.png           6  2025-12-08  12-58-30   \n",
       "2                E_63_St_1.png           7  2025-12-08  12-57-30   \n",
       "3  Queens_Midtown_Tunnel_1.png           7  2025-12-08  12-57-30   \n",
       "4     Queens_Plaza_North_1.png           5  2025-12-08  12-57-30   \n",
       "\n",
       "   description_total  \n",
       "0                  1  \n",
       "1                  2  \n",
       "2                  1  \n",
       "3                  1  \n",
       "4                  1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rows = []\n",
    "\n",
    "if not LABELS_DIR.exists():\n",
    "    raise FileNotFoundError(f\"Labels directory not found: {LABELS_DIR.resolve()}\")\n",
    "\n",
    "for json_path in LABELS_DIR.glob(\"*_labels.json\"):\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if not isinstance(data, list):\n",
    "        continue\n",
    "\n",
    "    for entry in data:\n",
    "        # Skip bad / issue images\n",
    "        if entry.get(\"error\") == \"YES\":\n",
    "            continue\n",
    "        if entry.get(\"car_amount\") is None:\n",
    "            continue\n",
    "\n",
    "        desc = entry.get(\"description\")\n",
    "        filename = entry.get(\"filename\")\n",
    "\n",
    "        # Try picture/<description>/<filename>, fall back to picture/<filename>\n",
    "        path1 = BASE_PICTURE_DIR / desc / filename\n",
    "        path2 = BASE_PICTURE_DIR / filename\n",
    "\n",
    "        if path1.exists():\n",
    "            img_path = path1\n",
    "        elif path2.exists():\n",
    "            img_path = path2\n",
    "        else:\n",
    "            # image not found â†’ skip\n",
    "            continue\n",
    "\n",
    "        all_rows.append({\n",
    "            \"filepath\": str(img_path),\n",
    "            \"description\": desc,\n",
    "            \"filename\": filename,\n",
    "            \"car_amount\": int(entry[\"car_amount\"]),\n",
    "            \"date\": entry.get(\"date\"),\n",
    "            \"time\": entry.get(\"time\"),\n",
    "            \"description_total\": entry.get(\"description_total\", None)\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(all_rows)\n",
    "print(\"Total labeled images:\", len(df))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df9d61ae-205e-48f8-b1a9-0711ecae11bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "\n",
    "class CarCountDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row[\"filepath\"]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        # Regression target (float)\n",
    "        target = torch.tensor(row[\"car_amount\"], dtype=torch.float32)\n",
    "        return img, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bfe3eb1-0466-410d-8d3e-29073482c1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset = CarCountDataset(df, transform=train_transform)\n",
    "\n",
    "val_size = int(len(full_dataset) * VAL_SPLIT)\n",
    "train_size = len(full_dataset) - val_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# Important: validation should use val_transform instead of train_transform\n",
    "# Wrap val_dataset to change transform\n",
    "val_dataset = CarCountDataset(df.iloc[val_dataset.indices], transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "len(train_dataset), len(val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7fa9df4-a6eb-4e28-ae9c-3af3e3e8f38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCarCounterCNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (regressor): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimpleCarCounterCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),   # 112x112\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),   # 56x56\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),   # 28x28\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),   # 14x14\n",
    "        )\n",
    "\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 14 * 14, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 1)  # output: predicted car count\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.regressor(x)\n",
    "        return x.squeeze(1)  # shape: (batch,)\n",
    "\n",
    "model = SimpleCarCounterCNN().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec43dbdf-d426-4f6c-8c97-1c18c35ddc2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/15 | Train MSE: 15.827 | Val MSE: 31.296 | Val MAE: 4.888\n",
      "  ðŸ”¥ New best model saved to models/car_count_cnn.pth\n",
      "Epoch 02/15 | Train MSE: 279.729 | Val MSE: 36.964 | Val MAE: 5.382\n",
      "Epoch 03/15 | Train MSE: 8.658 | Val MSE: 41.266 | Val MAE: 5.747\n",
      "Epoch 04/15 | Train MSE: 27.159 | Val MSE: 41.899 | Val MAE: 5.800\n",
      "Epoch 05/15 | Train MSE: 30.928 | Val MSE: 41.946 | Val MAE: 5.805\n",
      "Epoch 06/15 | Train MSE: 26.094 | Val MSE: 41.499 | Val MAE: 5.767\n",
      "Epoch 07/15 | Train MSE: 20.816 | Val MSE: 40.773 | Val MAE: 5.705\n",
      "Epoch 08/15 | Train MSE: 17.688 | Val MSE: 40.096 | Val MAE: 5.646\n",
      "Epoch 09/15 | Train MSE: 13.792 | Val MSE: 39.280 | Val MAE: 5.574\n",
      "Epoch 10/15 | Train MSE: 11.518 | Val MSE: 38.263 | Val MAE: 5.483\n",
      "Epoch 11/15 | Train MSE: 9.267 | Val MSE: 37.049 | Val MAE: 5.372\n",
      "Epoch 12/15 | Train MSE: 7.587 | Val MSE: 35.534 | Val MAE: 5.230\n",
      "Epoch 13/15 | Train MSE: 4.380 | Val MSE: 33.731 | Val MAE: 5.057\n",
      "Epoch 14/15 | Train MSE: 3.823 | Val MSE: 31.777 | Val MAE: 4.864\n",
      "  ðŸ”¥ New best model saved to models/car_count_cnn.pth\n",
      "Epoch 15/15 | Train MSE: 4.159 | Val MSE: 29.728 | Val MAE: 4.655\n",
      "  ðŸ”¥ New best model saved to models/car_count_cnn.pth\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_mae = 0.0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for images, targets in loader:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            total_mae += torch.abs(outputs - targets).sum().item()\n",
    "            n += images.size(0)\n",
    "\n",
    "    return total_loss / n, total_mae / n  # MSE, MAE\n",
    "\n",
    "\n",
    "best_val_mae = float(\"inf\")\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, targets in train_loader:\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    train_mse = running_loss / len(train_dataset)\n",
    "    val_mse, val_mae = evaluate(model, val_loader)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d}/{NUM_EPOCHS} \"\n",
    "          f\"| Train MSE: {train_mse:.3f} \"\n",
    "          f\"| Val MSE: {val_mse:.3f} \"\n",
    "          f\"| Val MAE: {val_mae:.3f}\")\n",
    "\n",
    "    # Save best model (based on MAE)\n",
    "    if val_mae < best_val_mae:\n",
    "        best_val_mae = val_mae\n",
    "        torch.save(model.state_dict(), MODEL_PATH)\n",
    "        print(f\"  ðŸ”¥ New best model saved to {MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0be60c7-cd07-4a12-b374-643b395f2287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCarCounterCNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU(inplace=True)\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (14): ReLU(inplace=True)\n",
       "    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (regressor): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=50176, out_features=512, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = SimpleCarCounterCNN().to(device)\n",
    "best_model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "best_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e62456e7-d267-424a-b09a-7f1767d14e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example path: picture/2nd_Ave_49_st/2nd_Ave_49_st_1.png\n",
      "Predicted cars: 1\n",
      "True cars: 9\n"
     ]
    }
   ],
   "source": [
    "single_image_transform = val_transform  # same as validation\n",
    "\n",
    "def predict_cars(image_path: str, model=best_model):\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    x = single_image_transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(x).item()\n",
    "\n",
    "    # We treat the output as a real number and round to nearest integer\n",
    "    return max(0, int(round(pred)))\n",
    "\n",
    "\n",
    "# Example usage: pick any image\n",
    "example_path = df.iloc[0][\"filepath\"]\n",
    "print(\"Example path:\", example_path)\n",
    "\n",
    "pred_count = predict_cars(example_path)\n",
    "print(\"Predicted cars:\", pred_count)\n",
    "print(\"True cars:\", df.iloc[0][\"car_amount\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "838b0646-f472-4210-93ff-0e8c3a4df077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S_Conduit_Ave_150_5.png                   true= 4,  pred= 1\n",
      "S_Conduit_Ave_150_2.png                   true= 2,  pred= 1\n",
      "S_Conduit_Ave_150_3.png                   true= 1,  pred= 1\n",
      "S_Conduit_Ave_150_9.png                   true= 3,  pred= 1\n",
      "Queens_Plaza_North_2.png                  true= 0,  pred= 1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "for i in range(5):\n",
    "    row = df.sample(1).iloc[0]\n",
    "    p = row[\"filepath\"]\n",
    "    true_cars = row[\"car_amount\"]\n",
    "    pred_cars = predict_cars(p)\n",
    "    print(f\"{Path(p).name:40s}  true={true_cars:2d},  pred={pred_cars:2d}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62721a99-07b6-40f1-95a0-fd993fee8545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
